{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Sign_test.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1J6ghGluOZnmtXBaNGzmnnKE9eSPxqSy5","authorship_tag":"ABX9TyNRUYzWyRfsk6iRn4DHnzfn"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"48MRqiY3IsFJ","executionInfo":{"status":"ok","timestamp":1614680713982,"user_tz":-330,"elapsed":4565,"user":{"displayName":"KARTHIKAYAN M UEC18215","photoUrl":"","userId":"03606072931601484034"}}},"source":["# import dependencies\r\n","from IPython.display import display, Javascript, Image\r\n","from google.colab.output import eval_js\r\n","from base64 import b64decode, b64encode\r\n","from keras.preprocessing import image\r\n","import cv2\r\n","import numpy as np\r\n","import matplotlib.pyplot as plt\r\n","import PIL\r\n","import io\r\n","import html\r\n","import time\r\n","import tensorflow"],"execution_count":185,"outputs":[]},{"cell_type":"code","metadata":{"id":"BaimCNOiI-sv","executionInfo":{"status":"ok","timestamp":1614680721877,"user_tz":-330,"elapsed":1699,"user":{"displayName":"KARTHIKAYAN M UEC18215","photoUrl":"","userId":"03606072931601484034"}}},"source":["# function to convert the JavaScript object into an OpenCV image\r\n","def js_to_image(js_reply):\r\n","  \"\"\"\r\n","  Params:\r\n","          js_reply: JavaScript object containing image from webcam\r\n","  Returns:\r\n","          img: OpenCV BGR image\r\n","  \"\"\"\r\n","  # decode base64 image\r\n","  image_bytes = b64decode(js_reply.split(',')[1])\r\n","  # convert bytes to numpy array\r\n","  jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)\r\n","  # decode numpy array into OpenCV BGR image\r\n","  img = cv2.imdecode(jpg_as_np, flags=1)\r\n","\r\n","  return img\r\n","\r\n","# function to convert OpenCV Rectangle bounding box image into base64 byte string to be overlayed on video stream\r\n","def bbox_to_bytes(bbox_array):\r\n","  \"\"\"\r\n","  Params:\r\n","          bbox_array: Numpy array (pixels) containing rectangle to overlay on video stream.\r\n","  Returns:\r\n","        bytes: Base64 image byte string\r\n","  \"\"\"\r\n","  # convert array into PIL image\r\n","  bbox_PIL = PIL.Image.fromarray(bbox_array, 'RGBA')\r\n","  iobuf = io.BytesIO()\r\n","  # format bbox into png for return\r\n","  bbox_PIL.save(iobuf, format='png')\r\n","  # format return string\r\n","  bbox_bytes = 'data:image/png;base64,{}'.format((str(b64encode(iobuf.getvalue()), 'utf-8')))\r\n","\r\n","  return bbox_bytes"],"execution_count":186,"outputs":[]},{"cell_type":"code","metadata":{"id":"qWNt8h6GJLWT","executionInfo":{"status":"ok","timestamp":1614691072047,"user_tz":-330,"elapsed":3641,"user":{"displayName":"KARTHIKAYAN M UEC18215","photoUrl":"","userId":"03606072931601484034"}}},"source":["# JavaScript to properly create our live video stream using our webcam as input\r\n","def video_stream():\r\n","  js = Javascript('''\r\n","    var video;\r\n","    var div = null;\r\n","    var stream;\r\n","    var captureCanvas;\r\n","    var imgElement;\r\n","    var labelElement;\r\n","    \r\n","    var pendingResolve = null;\r\n","    var shutdown = false;\r\n","    \r\n","    function removeDom() {\r\n","       stream.getVideoTracks()[0].stop();\r\n","       video.remove();\r\n","       div.remove();\r\n","       video = null;\r\n","       div = null;\r\n","       stream = null;\r\n","       imgElement = null;\r\n","       captureCanvas = null;\r\n","       labelElement = null;\r\n","    }\r\n","    \r\n","    function onAnimationFrame() {\r\n","      if (!shutdown) {\r\n","        window.requestAnimationFrame(onAnimationFrame);\r\n","      }\r\n","      if (pendingResolve) {\r\n","        var result = \"\";\r\n","        if (!shutdown) {\r\n","          captureCanvas.getContext('2d').drawImage(video, 0, 0, 1920, 1080);\r\n","          result = captureCanvas.toDataURL('image/jpeg', 0.8)\r\n","        }\r\n","        var lp = pendingResolve;\r\n","        pendingResolve = null;\r\n","        lp(result);\r\n","      }\r\n","    }\r\n","    \r\n","    async function createDom() {\r\n","      if (div !== null) {\r\n","        return stream;\r\n","      }\r\n","\r\n","      div = document.createElement('div');\r\n","      div.style.border = '2px solid black';\r\n","      div.style.padding = '3px';\r\n","      div.style.width = '100%';\r\n","      div.style.maxWidth = '600px';\r\n","      document.body.appendChild(div);\r\n","      \r\n","      const modelOut = document.createElement('div');\r\n","      modelOut.innerHTML = \"<span>Status:</span>\";\r\n","      labelElement = document.createElement('span');\r\n","      labelElement.innerText = 'No data';\r\n","      labelElement.style.fontWeight = 'bold';\r\n","      modelOut.appendChild(labelElement);\r\n","      div.appendChild(modelOut);\r\n","           \r\n","      video = document.createElement('video');\r\n","      video.style.display = 'block';\r\n","      video.width = div.clientWidth - 6;\r\n","      video.setAttribute('playsinline', '');\r\n","      video.onclick = () => { shutdown = true; };\r\n","      stream = await navigator.mediaDevices.getUserMedia(\r\n","          {video: { facingMode: \"environment\"}});\r\n","      div.appendChild(video);\r\n","\r\n","      imgElement = document.createElement('img');\r\n","      imgElement.style.position = 'absolute';\r\n","      imgElement.style.zIndex = 1;\r\n","      imgElement.onclick = () => { shutdown = true; };\r\n","      div.appendChild(imgElement);\r\n","      \r\n","      const instruction = document.createElement('div');\r\n","      instruction.innerHTML = \r\n","          '<span style=\"color: red; font-weight: bold;\">' +\r\n","          'Click here or on the video to stop</span>';\r\n","      div.appendChild(instruction);\r\n","      instruction.onclick = () => { shutdown = true; };\r\n","      \r\n","      video.srcObject = stream;\r\n","      await video.play();\r\n","\r\n","      captureCanvas = document.createElement('canvas');\r\n","      captureCanvas.width = 1920; //video.videoWidth;\r\n","      captureCanvas.height = 1080; //video.videoHeight;\r\n","      window.requestAnimationFrame(onAnimationFrame);\r\n","      \r\n","      return stream;\r\n","    }\r\n","    async function stream_frame(label, imgData) {\r\n","      if (shutdown) {\r\n","        removeDom();\r\n","        shutdown = false;\r\n","        return '';\r\n","      }\r\n","\r\n","      var preCreate = Date.now();\r\n","      stream = await createDom();\r\n","      \r\n","      var preShow = Date.now();\r\n","      if (label != \"\") {\r\n","        labelElement.innerHTML = label;\r\n","      }\r\n","            \r\n","      if (imgData != \"\") {\r\n","        var videoRect = video.getClientRects()[0];\r\n","        imgElement.style.top = videoRect.top + \"px\";\r\n","        imgElement.style.left = videoRect.left + \"px\";\r\n","        imgElement.style.width = videoRect.width + \"px\";\r\n","        imgElement.style.height = videoRect.height + \"px\";\r\n","        imgElement.src = imgData;\r\n","      }\r\n","      \r\n","      var preCapture = Date.now();\r\n","      var result = await new Promise(function(resolve, reject) {\r\n","        pendingResolve = resolve;\r\n","      });\r\n","      shutdown = false;\r\n","      \r\n","      return {'create': preShow - preCreate, \r\n","              'show': preCapture - preShow, \r\n","              'capture': Date.now() - preCapture,\r\n","              'img': result};\r\n","    }\r\n","    ''')\r\n","\r\n","  display(js)\r\n","  \r\n","def video_frame(label, bbox):\r\n","  data = eval_js('stream_frame(\"{}\", \"{}\")'.format(label, bbox))\r\n","  return data"],"execution_count":325,"outputs":[]},{"cell_type":"code","metadata":{"id":"DU3zNo1sJVHY","executionInfo":{"status":"ok","timestamp":1614691078431,"user_tz":-330,"elapsed":1614,"user":{"displayName":"KARTHIKAYAN M UEC18215","photoUrl":"","userId":"03606072931601484034"}}},"source":["import numpy as np\r\n","import cv2\r\n","#green\r\n","def hs1(path):\r\n","  import cv2\r\n","  import numpy as np\r\n","\r\n","  ## Read\r\n","  img = cv2.imread(path)\r\n","  \r\n","  ## convert to hsv\r\n","  hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\r\n","\r\n","  ## mask of green (36,25,25) ~ (86, 255,255)\r\n","  mask = cv2.inRange(hsv, np.array([25, 75, 100]), np.array([92, 255, 255]))\r\n","  #mask = cv2.inRange(hsv, np.array([94, 80, 2]), np.array([126, 255, 255]))\r\n","\r\n","  ## slice the green\r\n","  imask = mask>0\r\n","  green = np.zeros_like(img, np.uint8)\r\n","  green[imask] = img[imask]\r\n","\r\n","  ## save \r\n","  cv2.imwrite(\"green.png\", green)\r\n","\r\n","import numpy as np\r\n","import cv2\r\n","boundaries = [\r\n","    ([0, 120, 0], [140, 255, 100]),\r\n","    ([25, 0, 75], [180, 38, 255])\r\n","]\r\n","\r\n","#pink\r\n","def hs(frame):\r\n","    #frame = cv2.imread(frame)\r\n","    lower, upper = boundaries[0]\r\n","    lower = np.array(lower, dtype=\"uint8\")\r\n","    upper = np.array(upper, dtype=\"uint8\")\r\n","    mask1 = cv2.inRange(frame, lower, upper)\r\n","\r\n","    lower, upper = boundaries[1]\r\n","    lower = np.array(lower, dtype=\"uint8\")\r\n","    upper = np.array(upper, dtype=\"uint8\")\r\n","    mask2 = cv2.inRange(frame, lower, upper)\r\n","\r\n","    # for i,(lower, upper) in enumerate(boundaries):\r\n","    # \t# create NumPy arrays from the boundaries\r\n","    # \tlower = np.array(lower, dtype = \"uint8\")\r\n","    # \tupper = np.array(upper, dtype = \"uint8\")\r\n","\r\n","    # \t# find the colors within the specified boundaries and apply\r\n","    # \t# the mask\r\n","    # \tif(i==0):\r\n","    # \t\tprint \"Harish\"\r\n","    # \t\tmask1 = cv2.inRange(frame, lower, upper)\r\n","    # \telse:\r\n","    # \t\tprint \"Aadi\"\r\n","    # \t\tmask2 = cv2.inRange(frame, lower, upper)\r\n","    mask = cv2.bitwise_or(mask1, mask2)\r\n","    output = cv2.bitwise_and(frame, frame, mask=mask)\r\n","    # show the images\r\n","    # cv2.imshow(\"images\", mask)\r\n","    # cv2.imshow(\"images\", output)\r\n","    cv2.imwrite(\"green.png\", output)\r\n","    return output"],"execution_count":326,"outputs":[]},{"cell_type":"code","metadata":{"id":"g1IhjYzBK5Fj","executionInfo":{"status":"ok","timestamp":1614690635337,"user_tz":-330,"elapsed":929,"user":{"displayName":"KARTHIKAYAN M UEC18215","photoUrl":"","userId":"03606072931601484034"}}},"source":["classes = {1:'Colors', 0:'Women', 5:'Learn', 6:'Call', 8:'Drawer'}"],"execution_count":315,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I5a4u9T2Brrg","executionInfo":{"status":"ok","timestamp":1614684468180,"user_tz":-330,"elapsed":1678,"user":{"displayName":"KARTHIKAYAN M UEC18215","photoUrl":"","userId":"03606072931601484034"}},"outputId":"a02fdb52-af50-42a8-aab7-2bc3ade01a93"},"source":["model = tensorflow.compat.v1.keras.experimental.load_from_saved_model(\"/content/drive/MyDrive/2.30\")"],"execution_count":242,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/saving/saved_model_experimental.py:412: UserWarning: `tf.keras.experimental.load_from_saved_model` is deprecatedand will be removed in a future version. Please switch to `tf.keras.models.load_model`.\n","  warnings.warn('`tf.keras.experimental.load_from_saved_model` is deprecated'\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"tEm-2ZrzJZUb","colab":{"base_uri":"https://localhost:8080/","height":487},"executionInfo":{"status":"ok","timestamp":1614691558756,"user_tz":-330,"elapsed":40838,"user":{"displayName":"KARTHIKAYAN M UEC18215","photoUrl":"","userId":"03606072931601484034"}},"outputId":"ea406ec5-156c-46f9-a2c1-242feead8450"},"source":["from keras.preprocessing import image\r\n","import cv2\r\n","# start streaming video from webcam\r\n","video_stream()\r\n","# label for video\r\n","label_html = 'Capturing...'\r\n","# initialze bounding box to empty\r\n","bbox = ''\r\n","label_classes = ''\r\n","#label_map = classes#{j:i for i, j in classes.items()}\r\n","while True:\r\n","    \"\"\"#videoload\r\n","    name = '/content/drive/MyDrive/lsa64_cut/all_cut/014_008_002.mp4'\r\n","    cap = cv2.VideoCapture(name)\r\n","    ret, frame = cap.read()  # extract frame\r\n","    if ret is False:\r\n","        break\r\n","    frame = hs(frame)\"\"\"\r\n","\r\n","    #webcam\r\n","    js_reply = video_frame(label_html, bbox)\r\n","    if not js_reply:\r\n","        break\r\n","    # convert JS response to OpenCV Image\r\n","    img = PIL.Image.fromarray(js_to_image(js_reply[\"img\"]))\r\n","    img.save('green.png')\r\n","    hs1('green.png')\r\n","    frame = cv2.imread('green.png')\r\n","\r\n","    \r\n","    imge = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) \r\n","    print(imge.shape)\r\n","    cv2.imwrite('/content/drive/MyDrive/gesture.png', imge)\r\n","\r\n","    imgx = image.img_to_array(image.load_img('/content/drive/MyDrive/gesture.png', target_size=(28, 28)))\r\n","    img = tensorflow.image.rgb_to_grayscale(imgx)\r\n","    img = np.array(img / 255.)\r\n","    x = np.expand_dims(img, axis=0)\r\n","\r\n","    images = np.vstack([x])\r\n","    y = model.predict(images)\r\n","    if max(y[0]) > 0.75:\r\n","      y_classes = np.argmax(y, axis=-1)[0]\r\n","      print(y_classes)\r\n","      if y_classes in classes:\r\n","        #print(y)\r\n","        plt.axis('off')\r\n","        plt.imshow(imge)\r\n","        plt.show()\r\n","        print(classes[y_classes])\r\n","        label_classes += \" \" + classes[y_classes]\r\n","        if len(label_classes) > 24:\r\n","          label_classes = classes[y_classes]\r\n","    # create transparent overlay for bounding box\r\n","    bbox_array = np.zeros([1920,1080,4], dtype=np.uint8)\r\n","\r\n","\r\n","    # get face bounding box for overlay\r\n","    \r\n","    bbox_array = cv2.putText(bbox_array,label_classes,(15, 275),cv2.FONT_HERSHEY_SIMPLEX , 0.75,(255, 255, 255),2,cv2.LINE_AA) \r\n","\r\n","    bbox_array[:,:,3] = (bbox_array.max(axis = 2) > 0 ).astype(int) * 255\r\n","    # convert overlay of bbox into bytes\r\n","    bbox_bytes = bbox_to_bytes(bbox_array)\r\n","    # update bbox so next frame gets new overlay\r\n","    bbox = bbox_bytes"],"execution_count":334,"outputs":[{"output_type":"display_data","data":{"application/javascript":["\n","    var video;\n","    var div = null;\n","    var stream;\n","    var captureCanvas;\n","    var imgElement;\n","    var labelElement;\n","    \n","    var pendingResolve = null;\n","    var shutdown = false;\n","    \n","    function removeDom() {\n","       stream.getVideoTracks()[0].stop();\n","       video.remove();\n","       div.remove();\n","       video = null;\n","       div = null;\n","       stream = null;\n","       imgElement = null;\n","       captureCanvas = null;\n","       labelElement = null;\n","    }\n","    \n","    function onAnimationFrame() {\n","      if (!shutdown) {\n","        window.requestAnimationFrame(onAnimationFrame);\n","      }\n","      if (pendingResolve) {\n","        var result = \"\";\n","        if (!shutdown) {\n","          captureCanvas.getContext('2d').drawImage(video, 0, 0, 1920, 1080);\n","          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n","        }\n","        var lp = pendingResolve;\n","        pendingResolve = null;\n","        lp(result);\n","      }\n","    }\n","    \n","    async function createDom() {\n","      if (div !== null) {\n","        return stream;\n","      }\n","\n","      div = document.createElement('div');\n","      div.style.border = '2px solid black';\n","      div.style.padding = '3px';\n","      div.style.width = '100%';\n","      div.style.maxWidth = '600px';\n","      document.body.appendChild(div);\n","      \n","      const modelOut = document.createElement('div');\n","      modelOut.innerHTML = \"<span>Status:</span>\";\n","      labelElement = document.createElement('span');\n","      labelElement.innerText = 'No data';\n","      labelElement.style.fontWeight = 'bold';\n","      modelOut.appendChild(labelElement);\n","      div.appendChild(modelOut);\n","           \n","      video = document.createElement('video');\n","      video.style.display = 'block';\n","      video.width = div.clientWidth - 6;\n","      video.setAttribute('playsinline', '');\n","      video.onclick = () => { shutdown = true; };\n","      stream = await navigator.mediaDevices.getUserMedia(\n","          {video: { facingMode: \"environment\"}});\n","      div.appendChild(video);\n","\n","      imgElement = document.createElement('img');\n","      imgElement.style.position = 'absolute';\n","      imgElement.style.zIndex = 1;\n","      imgElement.onclick = () => { shutdown = true; };\n","      div.appendChild(imgElement);\n","      \n","      const instruction = document.createElement('div');\n","      instruction.innerHTML = \n","          '<span style=\"color: red; font-weight: bold;\">' +\n","          'Click here or on the video to stop</span>';\n","      div.appendChild(instruction);\n","      instruction.onclick = () => { shutdown = true; };\n","      \n","      video.srcObject = stream;\n","      await video.play();\n","\n","      captureCanvas = document.createElement('canvas');\n","      captureCanvas.width = 1920; //video.videoWidth;\n","      captureCanvas.height = 1080; //video.videoHeight;\n","      window.requestAnimationFrame(onAnimationFrame);\n","      \n","      return stream;\n","    }\n","    async function stream_frame(label, imgData) {\n","      if (shutdown) {\n","        removeDom();\n","        shutdown = false;\n","        return '';\n","      }\n","\n","      var preCreate = Date.now();\n","      stream = await createDom();\n","      \n","      var preShow = Date.now();\n","      if (label != \"\") {\n","        labelElement.innerHTML = label;\n","      }\n","            \n","      if (imgData != \"\") {\n","        var videoRect = video.getClientRects()[0];\n","        imgElement.style.top = videoRect.top + \"px\";\n","        imgElement.style.left = videoRect.left + \"px\";\n","        imgElement.style.width = videoRect.width + \"px\";\n","        imgElement.style.height = videoRect.height + \"px\";\n","        imgElement.src = imgData;\n","      }\n","      \n","      var preCapture = Date.now();\n","      var result = await new Promise(function(resolve, reject) {\n","        pendingResolve = resolve;\n","      });\n","      shutdown = false;\n","      \n","      return {'create': preShow - preCreate, \n","              'show': preCapture - preShow, \n","              'capture': Date.now() - preCapture,\n","              'img': result};\n","    }\n","    "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["(1080, 1920)\n","9\n","(1080, 1920)\n","9\n","(1080, 1920)\n","9\n","(1080, 1920)\n","9\n","(1080, 1920)\n","9\n","(1080, 1920)\n","9\n","(1080, 1920)\n","9\n","(1080, 1920)\n","9\n","(1080, 1920)\n","9\n","(1080, 1920)\n","9\n","(1080, 1920)\n","9\n","(1080, 1920)\n","9\n","(1080, 1920)\n","(1080, 1920)\n","(1080, 1920)\n","9\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pRGz2es5-VdH"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eMp1eHD6y89G","executionInfo":{"status":"aborted","timestamp":1614673969344,"user_tz":-330,"elapsed":3139,"user":{"displayName":"KARTHIKAYAN M UEC18215","photoUrl":"","userId":"03606072931601484034"}}},"source":[""],"execution_count":null,"outputs":[]}]}